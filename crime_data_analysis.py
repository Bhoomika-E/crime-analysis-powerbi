# -*- coding: utf-8 -*-
"""Crime_Data_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IGA1TA1SbZk3wCgJNYc3Br0YX4_d9pxQ
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 1. Load the pre-cleaned dataset
data = pd.read_csv("cleaned_crime.csv")

# 2. Basic checks (The data is already cleaned, so we just verify)
print("--- Dataset Overview ---")
print(data.info())
print(data['Crime'].value_counts().head(10)) # Top 10 Crimes

# 3. Visualization
plt.figure(figsize=(10,6))
sns.countplot(y='Crime', data=data, order=data['Crime'].value_counts().index[:10])
plt.title('Top 10 Crimes in Dataset')
plt.show()

# Heatmap of correlations (numeric only)
plt.figure(figsize=(10,8))
numerical = data.select_dtypes(include=[np.number])
sns.heatmap(numerical.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Feature Correlations')
plt.show()

# 4. Modeling Prep
features = ['year', 'month', 'day_of_week', 'hour', 'neighborhood_encoded', 'Reporting Area']
X = data[features]
y = data['crime_encoded']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 5. Training the Random Forest
model = RandomForestClassifier(n_estimators=100, max_depth=20, class_weight='balanced', random_state=42)
model.fit(X_train, y_train)

# 6. Evaluation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f'\nModel Accuracy: {accuracy * 100:.2f}%')
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# 7. Feature Importance
importances = pd.DataFrame({'Feature': features, 'Importance': model.feature_importances_})
print("\nFeature Importance:")
print(importances.sort_values('Importance', ascending=False))

# 8. Making a Specific Prediction
sample = pd.DataFrame({
    'year': [2024],
    'month': [6],
    'day_of_week': [2],
    'hour': [22],
    'neighborhood_encoded': [3],
    'Reporting Area': [105.0]
})

pred_encoded = model.predict(sample)

# To get the name back, we map the encoded value to the original name from the dataframe
crime_map = dict(zip(data['crime_encoded'], data['Crime']))
predicted_crime_name = crime_map.get(pred_encoded[0])

print(f"\nPredicted Crime for Sample: {predicted_crime_name}")